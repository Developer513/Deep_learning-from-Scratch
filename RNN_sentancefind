{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RNN_sentancefind","provenance":[],"private_outputs":true,"collapsed_sections":[],"authorship_tag":"ABX9TyNFy9RLGMRCerrqauObC29P"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"_O3BYtNJylOF","colab_type":"code","colab":{}},"source":["# 코드 : 비트패턴\n","# 인코딩 : 어떤 장치나 기계가 이해할 수 있도록 비트패턴을 변한하는 것 \n","# 워드 임베딩: 동일한 범주나 비슷한 의미의 단어들을 인코딩 했을때도 연관성이 있도록\n","# 단어 단위로 인코딩 하는것 문자열을 수치계산이 가능한 수열로 변환한다. \n","# 재귀 신경망 \n","# daily dialog"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yagq4A_S3-sU","colab_type":"code","colab":{}},"source":["import torch\n","from torch import nn\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"31fkeGoX4ajQ","colab_type":"code","colab":{}},"source":["text = ['hey how are you', 'good i am fine',\n","        'have a nice day','thank you',\n","        'why are you whispering?','they cannot hear you',\n","        'here is some kinds of magictrick','immovable object meets unstoppable force']\n","chars = set(' '.join(text)) # 텍스트 리스트에서 공백과 같은 \n","int2char = dict(enumerate(chars)) # \n","print(int2char)\n","char2int = {char: ind for ind, char in int2char.items()}\n","print(char2int)\n","maxlen = len(max(text, key = len))\n","print(\"The longest string has {} characters\".format(maxlen))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dl4EFP0X4pes","colab_type":"code","colab":{}},"source":["for i in range(len(text)):\n","  while len(text[i]) < maxlen:\n","    text[i] += ' '\n","\n","input_seq = []\n","target_seq = []\n","\n","for i in range(len(text)):\n","  input_seq.append(text[i][:-1])\n","  target_seq.append(text[i][1:])\n","  print(\"Input Sequence: {}\\nTarget Sequence: {}\".format(input_seq[i], target_seq[i]))\n","\n","for i in range(len(text)):\n","  input_seq[i] = [char2int[character] for character in input_seq[i]]\n","  target_seq[i] = [char2int[character] for character in target_seq[i]]\n","\n","dict_size = len(char2int)\n","seq_len = maxlen -1\n","batch_size = len(text)\n","\n","def one_hot_encode(sequence, dict_size, seq_len, batch_size):\n","  features = np.zeros((batch_size, seq_len, dict_size), dtype = np.float32)\n","\n","  for i in range(batch_size):\n","    for u in range(seq_len):\n","      features[i,u, sequence[i][u]] = 1\n","  return features"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5FpQq0UV7yjl","colab_type":"code","colab":{}},"source":["input_seq = one_hot_encode(input_seq, dict_size, seq_len, batch_size)\n","print(\"Inpt shape: {} --> (Batch_size, Sequence Length, One-Hot Encoding Size)\".format(input_seq.shape))\n","input_seq = torch.from_numpy(input_seq)\n","target_seq = torch.Tensor(target_seq)\n","\n","is_cuda = torch.cuda.is_available\n","if is_cuda:\n","  device = torch.device(\"cuda\")\n","  print(\"GPU is available\")\n","else: \n","  device = torch.device(\"cpu\")\n","  print(\"GPU is not available\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HSOEG7S49RrA","colab_type":"code","colab":{}},"source":["class Model(nn.Module):\n","  def __init__(self, input_size, output_size, hidden_dim, n_layers):\n","    super(Model, self).__init__()\n","    self.hidden_dim = hidden_dim\n","    self.n_layers = n_layers\n","    self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first = True)\n","    self.fc = nn.Linear(hidden_dim, output_size)\n","  \n","  def forward(self,x):\n","    batch_size = x.size(0)\n","    hidden = self.init_hidden(batch_size)\n","    out, hidden = self.rnn(x, hidden)\n","    out = out.contiguous().view(-1, self.hidden_dim)\n","    out = self.fc(out)\n","    return out, hidden\n","  \n","  def init_hidden(self, batch_size):\n","    hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n","    hidden = hidden.to(device)\n","    return hidden"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZcIVn9g4_TK7","colab_type":"code","colab":{}},"source":["model = Model(input_size = dict_size, output_size = dict_size, hidden_dim = 12, n_layers = 1)\n","model = model.to(device)\n","n_epochs = 1000\n","lr = 0.01\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n","\n","input_seq = input_seq.to(device)\n","for epoch in range(1, n_epochs + 1):\n","  optimizer.zero_grad()\n","  output, hidden = model(input_seq)\n","  output = output.to(device)\n","  target_seq = target_seq.to(device)\n","  loss = criterion(output, target_seq.view(-1).long())\n","  loss.backward()\n","  optimizer.step()\n","  if epoch%10 == 0:\n","    print('Epoch: {}/{}............'.format(epoch, n_epochs),end = ' ')\n","    print(\"Loss: {:.4f}\".format(loss.item()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FrUj7EHYA3xS","colab_type":"code","colab":{}},"source":["def predict(model, character):\n","  character = np.array([[char2int[c] for c in character]])\n","  character = one_hot_encode(character, dict_size, character.shape[1],1)\n","  character = torch.from_numpy(character)\n","  character = character.to(device)\n","\n","  out,hidden = model(character)\n","  prob = nn.functional.softmax(out[-1], dim = 0).data\n","  char_indx = torch.max(prob, dim = 0)[1].item()\n","  return int2char[char_indx], hidden\n","\n","def sample(model, out_len, start = 'hey'):\n","  model.eval()\n","  start = start.lower()\n","  chars = [ch for ch in start]\n","  size = out_len - len(chars)\n","  for ii in range(size):\n","    char, h = predict(model, chars)\n","    chars.append(char)\n","  return ''.join(chars)\n","\n","sample(model, 40, 'immovable')"],"execution_count":null,"outputs":[]}]}