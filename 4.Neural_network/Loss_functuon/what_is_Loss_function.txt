손실 함수란 신경망이 학습할 수 있도록 해주는 지표이다.
머신러닝 모델의 출력값과 사용자가 원하는 출력값의
차이, 즉 오차를 말한다.
이 손실 함수 값이 최소화되도록 하는 가중치와 편향을 
찾는 것이 바로 학습이다. 
일반적인 손실 함수로 평균 제곱 오차나 교차 엔트로피 오차를 사용한다.
 
손실함수를 쓰는 이유 
궁극적인 목적은 높은 정확도를 끌어내는 매개변수를 찾는 것이다. 
그러면 정확도(accuracy) 라는 지표를 놔두고 왜 손실함수의 값을 사용하는것일까?
이 의문은 미분의 역할에서 해결할 수 있다. 
신경망학습에서는 최적의 매개변수를 탐색할 때 손실함수의 값을 
가능한 작게 하는 매개변수 값을 찾는다. 이때 매개변수의 미분을  계산하고
그 미분값을 단서로 매개변수의 값을 서서히 갱신하는 과정을 반복한다. 
어떤 신경망이 학습한다고 했을 때 가중치의 손실함수의 미분의 의미는
가중치의 값을 아주 조금 변화시켰을 대 어떻게 변하는지를 의미한다. 
만약 미분값이 음수이면 그 가중치를 양의 방향으로 변화시켜 손실함수  값을 줄일수 있다.
반대로 미분값이 양수이면 가중치를 음의 방향으로 변화시켜 손실함수의 값을 줄일 수 있다.
근데 미분값이 0이변 가중치를 어느쪽으로 변화시켜도 줄어들지 않는다 따라서 가중치 갱신은 멈춘다. 
그렇다면 정확도를 지표로 삼으면 학습이 잘 될까?
